{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "narrative-rapid",
   "metadata": {},
   "source": [
    "## 1. 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "hindu-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-azerbaijan",
   "metadata": {},
   "source": [
    "## 2. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "imported-religion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기 : 187088\n"
     ]
    }
   ],
   "source": [
    "txt_list = glob.glob(\"./data/lyrics/*\")\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "for file in txt_list:\n",
    "    with open(file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "        \n",
    "print(f\"데이터 크기 : {len(raw_corpus)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-business",
   "metadata": {},
   "source": [
    "## 3. 텍스트 전처리 - 소문자화, 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "stylish-livestock",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175986"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 빈칸 제거\n",
    "raw_corpus = [i for i in raw_corpus if len(i) != 0]\n",
    "len(raw_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "interracial-fisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kdnuggets.com/2019/04/text-preprocessing-nlp-machine-learning.html\n",
    "def text_preprocessing(corpus):\n",
    "    \"\"\"\n",
    "    desc: \n",
    "        -소문자화, 특수문제제거, 불용어제거, Stemming 기법들 적용하여 전처리 실시\n",
    "    args:\n",
    "        - list()\n",
    "    return:\n",
    "        - list()\n",
    "    \"\"\"\n",
    "    corpus = corpus.lower()\n",
    "    corpus = re.sub('[^a-z?\\'!.,¿]+', ' ', corpus)\n",
    "    \n",
    "    # 혼자 있는 따옴표 제거\n",
    "    corpus = re.sub(' \\' ', ' ', corpus)\n",
    "\n",
    "    \n",
    "    # 혼자있는 자음 제거\n",
    "    tmp = None\n",
    "    while tmp != corpus:\n",
    "        tmp = corpus\n",
    "        corpus = re.sub(\" [xobgnerclfpkyvjhwzqstmd] \", ' ', corpus)\n",
    "    \n",
    "    corpus = re.sub(\"^[u] \", \"you\", corpus)\n",
    "    corpus = re.sub(\" [u]$\", \"you\", corpus)\n",
    "    corpus = re.sub(\"[ ]+\", ' ', corpus)\n",
    "    corpus = corpus.strip()\n",
    "    \n",
    "    \n",
    "    # u를 you로 전환\n",
    "    # corpus = re.sub(\"^<start> u \", '<start> you ', corpus)\n",
    "    # corpus = re.sub(\" u <end>$\", ' you <end>', corpus)\n",
    "    corpus = '<start> ' + corpus + ' <end>'\n",
    "    corpus = corpus.strip()\n",
    "    return corpus\n",
    "\n",
    "# 전처리 적용\n",
    "tmp = list(map(text_preprocessing, raw_corpus))\n",
    "# 전처리 적용 후 단어가 없는 경우 제거\n",
    "clean_corpus = []\n",
    "for i in tmp:\n",
    "    if len(i.split(\" \")) > 2:\n",
    "        clean_corpus += [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "neutral-subdivision",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기 : 175986\n"
     ]
    }
   ],
   "source": [
    "print(f\"데이터 크기 : {len(clean_corpus)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-delivery",
   "metadata": {},
   "source": [
    "## 4. 텍스트 전처리 - 토큰화, 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "prospective-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vocabulary(clean_corpus):\n",
    "    split_corpus = list(map(lambda x : x.split(),clean_corpus))\n",
    "\n",
    "    tmp = defaultdict()\n",
    "    for corpus in split_corpus:\n",
    "        for word in corpus:\n",
    "            if word not in tmp:\n",
    "                tmp[word] = corpus.count(word)\n",
    "            else:\n",
    "                tmp[word] += corpus.count(word)\n",
    "\n",
    "    tmp = dict(tmp)\n",
    "    word_count = sorted(tmp.items(), key = lambda x : x[1], reverse = True)\n",
    "    return split_corpus, word_count\n",
    "\n",
    "split_corpus, word_count = count_vocabulary(clean_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hearing-lightning",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175986/175986 [00:00<00:00, 205176.08it/s]\n"
     ]
    }
   ],
   "source": [
    "def vocab(word_count, num=7000):\n",
    "    \"\"\"\n",
    "    단어장 생성\n",
    "    \"\"\"\n",
    "    word_index = dict()\n",
    "    index_word = dict()\n",
    "    for ind, i in enumerate(word_count):\n",
    "        word_index[i[0]] = ind + 2\n",
    "        index_word[ind + 2] = i[0]\n",
    "    # padding 토큰\n",
    "    word_index[\"<pad>\"] = 0\n",
    "    index_word[0] = \"<pad>\"\n",
    "    # unknown 토큰\n",
    "    word_index[\"<unk>\"] = 1\n",
    "    index_word[1] = \"<unk>\"\n",
    "\n",
    "    vocab = dict(word_count[:num]) # 사용할 단어의 개수\n",
    "    return vocab, word_index, index_word\n",
    "\n",
    "vocab, word_index, index_word = vocab(word_count, num = 14000)\n",
    "\n",
    "def vectorization(split_corpus, vocab, maxlen = None):\n",
    "    \"\"\"\n",
    "    텍스트 말뭉치에서 벡터 말뭉치로 전환시키며 없는 단어는 <unk> 부여\n",
    "    \"\"\"\n",
    "    vector_corpus = []\n",
    "    for corpus in tqdm(split_corpus):\n",
    "        tmp = []\n",
    "        if len(corpus) < 15:\n",
    "            for word in corpus:\n",
    "                if word in vocab:\n",
    "                    tmp += [word_index[word]]\n",
    "                else:\n",
    "                    tmp += [1]\n",
    "            vector_corpus += [tmp]\n",
    "\n",
    "\n",
    "    vector_corpus = tf.keras.preprocessing.sequence.pad_sequences(vector_corpus, maxlen, padding=\"pre\")\n",
    "    return vector_corpus\n",
    "\n",
    "vector_corpus = vectorization(split_corpus, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "roman-castle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158835, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "collected-percentage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,    51,    61,     3],\n",
       "       [    0,     0,     0, ...,    17,    17,     3],\n",
       "       [    0,     0,     0, ...,   101, 12040,     3],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,    30,   114,     3],\n",
       "       [    0,     0,     0, ...,    10,   163,     3],\n",
       "       [    2,     7,    40, ...,   325,   325,     3]], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-patrol",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i, j in word_count:\n",
    "#     if len(i) == 1:\n",
    "#         print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-integration",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # u, x 만 있는 단어 찾기\n",
    "# tmp = list(map(lambda x : len(re.findall(\" q \", x)), clean_corpus))\n",
    "# for i in range(len(clean_corpus)):\n",
    "#     if tmp[i] != 0:\n",
    "#         print(i, clean_corpus[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-spice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_corpus\n",
    "\n",
    "# from gensim.models import Word2Vec\n",
    "# word2vec_model = Word2Vec(vector_size = 300, window=5, min_count = 1, workers = 2)\n",
    "# word2vec_model.build_vocab(split_corpus)\n",
    "# word2vec_model.intersect_word2vec_format('./word2vec/GoogleNews-vectors-negative300.bin', lockf=1.0, binary=True)\n",
    "\n",
    "# word2vev = Word2Vec(split_corpus)\n",
    "\n",
    "# word2vev.wv\n",
    "\n",
    "# tmp = []\n",
    "# for corpus in split_corpus[:10]:\n",
    "#     tmp += [list(map(lambda x: word2vev.wv[x], corpus))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "under-silver",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 갯수 : 158835\n",
      "문장 길이 : 14\n",
      "텍스트에서 변환된 시퀀스 가장 큰 인덱스값 : 14001\n"
     ]
    }
   ],
   "source": [
    "print(f\"문장 갯수 : {vector_corpus.shape[0]}\\n문장 길이 : {vector_corpus.shape[1]}\")\n",
    "print(f\"텍스트에서 변환된 시퀀스 가장 큰 인덱스값 : {np.max(vector_corpus)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-blind",
   "metadata": {},
   "source": [
    "## 5. 학습데이터셋, 테스트데이터셋 분리 및 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "oriental-colony",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "random_index = np.random.choice(range(len(vector_corpus)), 20000, replace=False)\n",
    "mini_vector_corpus = vector_corpus[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "scheduled-discrimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_input = vector_corpus[:, :-1]\n",
    "tgt_input = vector_corpus[:, 1:]\n",
    "\n",
    "tr_src_input,te_src_input,tr_tgt_input,te_tgt_input = train_test_split(src_input,\n",
    "                                                                      tgt_input,\n",
    "                                                                      test_size = 0.2,\n",
    "                                                                      random_state = seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "extensive-license",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127068, 13) (127068, 13)\n",
      "(31767, 13) (31767, 13)\n"
     ]
    }
   ],
   "source": [
    "print(tr_src_input.shape, tr_tgt_input.shape)\n",
    "print(te_src_input.shape, te_tgt_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "later-ticket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 13), (64, 13)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer_size = len(tr_src_input)\n",
    "batch_size = 64\n",
    "steps_per_epoch = len(tr_src_input) // batch_size\n",
    "\n",
    "vocab_size = len(word_count)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((tr_src_input, tr_tgt_input))\n",
    "dataset = dataset.shuffle(buffer_size)\n",
    "dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-ecology",
   "metadata": {},
   "source": [
    "## 6. 모델 구조 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "continuous-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    embedding_size = 256\n",
    "    hidden_size = 1024\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=(tr_src_input.shape[1]))\n",
    "    layer = tf.keras.layers.Embedding(vocab_size, embedding_size)(inputs)\n",
    "#   layer = tf.keras.layers.BatchNormalization()(layer) \n",
    "    layer = tf.keras.layers.LSTM(hidden_size, return_sequences=True)(layer)\n",
    "#   layer = tf.keras.layers.LSTM(hidden_size, return_sequences=True, dropout=0.2)(layer)\n",
    "    layer = tf.keras.layers.Dropout(0.2)(layer)\n",
    "\n",
    "#   layer = tf.keras.layers.BatchNormalization()(layer) \n",
    "    layer = tf.keras.layers.LSTM(hidden_size, return_sequences=True)(layer)\n",
    "#   layer = tf.keras.layers.LSTM(hidden_size, return_sequences=True, dropout=0.2)(layer)\n",
    "    layer = tf.keras.layers.Dropout(0.2)(layer)\n",
    "\n",
    "#   layer = tf.keras.layers.BatchNormalization()(layer)\n",
    "    outputs = tf.keras.layers.Dense(vocab_size, kernel_initializer=\"he_normal\")(layer)\n",
    "#   outputs = tf.keras.layers.Dense(vocab_size)(layer)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-emerald",
   "metadata": {},
   "source": [
    "## 7. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "framed-niagara",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1985/1985 [==============================] - 489s 245ms/step - loss: 3.7693 - val_loss: 3.1054\n",
      "Epoch 2/10\n",
      "1985/1985 [==============================] - 486s 245ms/step - loss: 3.0089 - val_loss: 2.8580\n",
      "Epoch 3/10\n",
      "1985/1985 [==============================] - 486s 245ms/step - loss: 2.7026 - val_loss: 2.7032\n",
      "Epoch 4/10\n",
      "1985/1985 [==============================] - 485s 244ms/step - loss: 2.4324 - val_loss: 2.6010\n",
      "Epoch 5/10\n",
      "1985/1985 [==============================] - 485s 244ms/step - loss: 2.2169 - val_loss: 2.5302\n",
      "Epoch 6/10\n",
      "1985/1985 [==============================] - 485s 244ms/step - loss: 2.0353 - val_loss: 2.4892\n",
      "Epoch 7/10\n",
      "1985/1985 [==============================] - 486s 245ms/step - loss: 1.8900 - val_loss: 2.4620\n",
      "Epoch 8/10\n",
      "1985/1985 [==============================] - 485s 244ms/step - loss: 1.7681 - val_loss: 2.4491\n",
      "Epoch 9/10\n",
      "1985/1985 [==============================] - 486s 245ms/step - loss: 1.6716 - val_loss: 2.4380\n",
      "Epoch 10/10\n",
      "1985/1985 [==============================] - 486s 245ms/step - loss: 1.5951 - val_loss: 2.4389\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAvcElEQVR4nO3dd3RVVdrH8e+TAqkEUggkIYTQCdUECNItgFiAARUVxzISnHHsYp95R2ec0dGxV5pjxUGKDRRQaSo1kRZ6CZBQEgKBkJC+3z/uRUJIz01OcvN81ror5552n9wFv3Oy9zn7iDEGpZRSzsvF6gKUUkrVLg16pZRychr0Sinl5DTolVLKyWnQK6WUk3OzuoDSBAYGmoiICKvLUEqpBiM+Pv64MSaotGX1MugjIiLYsGGD1WUopVSDISIHylqmTTdKKeXkNOiVUsrJadArpZSTq5dt9EopVVX5+fkkJyeTk5NjdSm1ysPDg7CwMNzd3Su9jQa9UsopJCcn4+vrS0REBCJidTm1whhDeno6ycnJtGvXrtLbadONUsop5OTkEBAQ4LQhDyAiBAQEVPmvFg16pZTTcOaQP6c6v6PTBH1hkeGd5XvZeCjD6lKUUqpecZqgz8or4MPVSTw8ZyM5+YVWl6OUamQyMjJ4++23q7zd6NGjycjIcHxBxThN0DfzcOfFCb3Ym5bFi4t3Wl2OUqqRKSvoCwoKyt1u0aJFNG/evJaqsnGaoAcY1DGQW2PbMuvn/azZl251OUqpRuTxxx9n79699O7dm759+zJ48GCuu+46unXrBsDYsWOJjo4mKiqKadOm/bZdREQEx48fJykpia5duzJ58mSioqIYMWIEZ8+edUhtTnd55ROju7BydxqPfL6J7x4Ygk9Tp/sVlVIVeObrRLYdPu3QfXYLacb/XRtV5vLnn3+erVu3snHjRpYvX87VV1/N1q1bf7sMctasWfj7+3P27Fn69u3L+PHjCQgIuGAfu3fvZvbs2UyfPp0bbriBefPmMWnSpBrX7lRn9ABeTdz4z/W9SMk4y3MLt1tdjlKqkerXr98F17q//vrr9OrVi9jYWA4dOsTu3bsv2qZdu3b07t0bgOjoaJKSkhxSi1Oe7sZE+BM3OJL3Vu5jRFQwwzu3tLokpVQdKu/Mu654e3v/Nr18+XK+//57Vq9ejZeXF8OGDSv1WvimTZv+Nu3q6uqwphunO6M/58ErO9Ep2IfH5m4mIzvP6nKUUk7O19eXzMzMUpedOnWKFi1a4OXlxY4dO1izZk2d1ua0Qe/h7srLN/TmRFYe//dVotXlKKWcXEBAAAMHDqR79+5MnTr1gmWjRo2ioKCArl278vjjjxMbG1untYkxpk4/sDJiYmKMox488tr3u3nl+128fcsljO7R2iH7VErVP9u3b6dr165Wl1EnSvtdRSTeGBNT2vpOe0Z/zp+Gt6dHqB9Pf7GVtMxcq8tRSqk65/RB7+7qwss39OJMbgFPLthCffwLRimlapPTBz1Ax2Bfpo7ozNJtx5ifkGJ1OUopVacaRdAD3DmoHf0i/PnbV4kcznDMJUtKKdUQNJqgd3URXry+J4XG8OjczdqEo5RqNBpN0AO0DfDmydFd+WnPcT5ee9DqcpRSqk5UGPQi4iEi60Rkk4gkisgzpazzkIhsE5HNIvKDiLQttqxQRDbaX185+heoqlv6hzO4YyD/XLidpONZVpejlHIS1R2mGODVV18lOzvbwRWdV5kz+lzgMmNML6A3MEpESl7t/ysQY4zpCcwF/l1s2VljTG/76zpHFF0TIsK/J/TEzVV45PNNFBZpE45Squbqc9BXONaNsTVmn7G/dbe/TIl1lhV7uwao+XBrtai1nyfPXBfFQ3M2MWPVPqYMbW91SUqpBq74MMVXXnklLVu2ZM6cOeTm5jJu3DieeeYZsrKyuOGGG0hOTqawsJC//OUvHDt2jMOHDzN8+HACAwNZtmxZxR9WRZUa1ExEXIF4oAPwljFmbTmr/wH4tth7DxHZABQAzxtjvijjM+KAOIDw8PDKlFUj4/qEsjjxKP9ZsovhXVrSKdi31j9TKVVHvn0cjm5x7D5b9YCrni9zcfFhipcsWcLcuXNZt24dxhiuu+46Vq5cSVpaGiEhISxcuBCwjYHj5+fHyy+/zLJlywgMDHRszXaV6ow1xhQaY3oDYUA/Eele2noiMgmIAV4sNrut/bbcm4FXRaTU02djzDRjTIwxJiYoKKgqv0O1iAjPjeuBj4cbD83ZSH5hUa1/plKqcViyZAlLliyhT58+XHLJJezYsYPdu3fTo0cPli5dymOPPcaqVavw8/Ork3qqNEyxMSZDRJYBo4CtxZeJyBXAU8BQY0xusW1S7D/3ichyoA+wt4Z1O0SgT1P+Oa47d3+cwJs/7uHBKztZXZJSyhHKOfOuC8YYnnjiCaZMmXLRsoSEBBYtWsTTTz/N5Zdfzl//+tdar6cyV90EiUhz+7QncCWwo8Q6fYD3gOuMManF5rcQkab26UBgILDNYdU7wKjurRnXJ5Q3l+1hS/Ipq8tRSjVQxYcpHjlyJLNmzeLMGVv3ZkpKCqmpqRw+fBgvLy8mTZrE1KlTSUhIuGjb2lCZM/rWwAf2dnoXYI4x5hsReRbYYIz5CltTjQ/wuYgAHLRfYdMVeE9EiuzbPm+MqVdBD/C3a6NYvTedh+Zs5Ot7B+Hh7mp1SUqpBqb4MMVXXXUVN998MwMGDADAx8eHjz/+mD179jB16lRcXFxwd3fnnXfeASAuLo5Ro0YREhJSK52xTj9McWWt2JXGbbPWETckkidHN46hTpVyJjpMcSMepriyhnYK4ub+4UxftY/1SSesLkcppRxGg76Yp0Z3JayFJw/P2URWboHV5SillENo0Bfj3dSNlyb04tDJbP717Xary1FKVVF9bIp2tOr8jhr0JfSPDOAPA9vx8ZqDrNyVZnU5SqlK8vDwID093anD3hhDeno6Hh4eVdquStfRNxaPjOzM8l1pPDp3M4sfHIKfp7vVJSmlKhAWFkZycjJpac59gubh4UFYWFiVttGgL4WHuysv39CLcW//wjNfJ/LyDb2tLkkpVQF3d3fatWtndRn1kjbdlKFnWHPuGd6B+QkpLE48anU5SilVbRr05fjz8A5EhTTjyflbSD+TW/EGSilVDzlX0BfmO3R3TdxcePmG3mTmFPDUgq1O3cmjlHJezhP0edkw80pY+RI4MJA7t/LloRGd+C7xKF9uPOyw/SqlVF1xnqAXgYAO8OPfYe4dkOe4xwROHhxJdNsW/PXLrRw9leOw/SqlVF1wnqB394TfTYcrn4XEL2DmSDh5wCG7dnUR/nN9L/ILDY/N26xNOEqpBsV5gh5sZ/UD74db5kLGQZg+HJJ+csiuIwK9eWJ0F1bsSmP2ukMO2adSStUF5wr6czpeAZN/BK8A+HAMrJvukHb7Sf3bMrBDAP9YuI2D6bX3IF+llHIk5wx6gMAOcNcP0OEKWPQIfH0fFNTsEkkXF+HfE3rhKsIjczdRVKRNOEqp+s95gx7AoxlMnA2DH4GED+GDayHzWI12Gdrck79e2411+08w6+f9DipUKaVqj3MHPYCLC1z+F7j+v7anwk8bBinxNdrlhOgwrugazL8X72RPau09/ksppRzB+YP+nKhx8Icl4OIGs66CTf+r9q5EhH/+rjveTVx5aM4mCgqLHFioUko5VmUeDu4hIutEZJOIJIrIM6Ws01RE/icie0RkrYhEFFv2hH3+ThEZ6eD6q6ZVD4hbBm36wYI4WPwUFFbvASMtfT34x9gebE4+xTvL9zq4UKWUcpzKnNHnApcZY3oBvYFRIhJbYp0/ACeNMR2AV4AXAESkGzARiAJGAW/bHzJuHe9AuHUB9IuD1W/Cp9fD2ZPV2tXVPVtzXa8QXvthN1tTTjm4UKWUcowKg97YnLG/dbe/Sl5uMgb4wD49F7hcRMQ+/zNjTK4xZj+wB+jnkMprwtUdRr8I174O+1fBtOGQWr0nSj07Jgp/7yY8PGcTuQWFDi5UKaVqrlJt9CLiKiIbgVRgqTFmbYlVQoFDAMaYAuAUEFB8vl2yfV79EH0b3L7QNlzCjCtgx8Iq76K5VxNeGN+TnccyeWXp7looUimlaqZSQW+MKTTG9AbCgH4i0t3RhYhInIhsEJENdfqEmPD+ELccAjvCZzfDin9DUdU6V4d3acnEvm2YtnIv8QdO1E6dSilVTVW66sYYkwEsw9beXlwK0AZARNwAPyC9+Hy7MPu80vY9zRgTY4yJCQoKqkpZNecXCnd8Cz0nwrLn4PPbIPdMxdsV89TVXWnt58nDczaRnVe9Dl6llKoNlbnqJkhEmtunPYErgR0lVvsKuM0+PQH40dhG/voKmGi/Kqcd0BFY56DaHcvdE8a9CyP/CTu+gZkj4ETlb4jy9XDnpet7kZSezQvflvx6lFLKOpU5o28NLBORzcB6bG3034jIsyJynX2dmUCAiOwBHgIeBzDGJAJzgG3Ad8A9xpj622MpAgPugUnz4HSKbVC0fcsrvfmA9gHcMTCCD1Yf4JvNOna9Uqp+kPo45G5MTIzZsGGDtUWk77W12R/fbTvL7z/FdiCoQE5+IZNmrCX+4EmeG9uDm/uH10GxSqnGTkTijTExpS1rPHfGVlVAe7jre+g0Cr57DL68B/IrfuiIh7srH/2hP8M6BfHkgi28tWyPjl+vlLKUBn15mvrCjR/D0Mdg4yfw36vh9JEKN/Ns4sq038cwrk8oLy7eyT8WbteRLpVSltGgr4iLCwx/Em74yHZT1bRhkFxxs5K7qwv/ub4XdwyMYOZP+3nk803k65g4SikLaNBXVrfr4K6l4NYU3r8Kfv2kwk1cXIS/XtONR0Z0Yv6vKdz9UTw5+fW3L1op5Zw06KsiOMp2c1X4APjyT/Dt4xUOiiYi/PmyjvxjbHd+3JnKrTPXcupsft3Uq5RSaNBXnZc/TJoPsX+Cte/Ax7+D7Irvhp0U25Y3burDxkMZ3PjealIzK+7YVUopR9Cgrw5XNxj1LxjzNhxcbWu3P5ZY4WbX9Axh1u19OXgimwnvrNbnziql6oQGfU30ucU2dEJBLsy4ErZ9VeEmgzsG8enkWE7n5DP+3V/YfuR0HRSqlGrMNOhrKizG1m7fsivMuRWW/bPCQdF6t2nO3LsH4OYi3PDeatYn6UBoSqnao0HvCM1a24Y77n0LrHgB/jcJstLL3aRDS1/m/vFSgnybMmnGWn7cUbOHliulVFk06B3F3QPGvAWjXoBd38FrPeGHv5fbURva3JPPpwygcytfJn8Yz/yE5DosWCnVWGjQO5IIxN4Nf1oNHUfAqpfgtV6w7F9wNqPUTQJ8mvLp5Fj6t/PnoTmbmPlT5UfMVEqpytCgrw1BneH69+GPv0DkMFjxvO0Mf8WLkHNx56tPUzfev6Mvo6Ja8fdvtvHS4p06Po5SymE06GtTcBTc+BFMWQVtB8Gyf9gCf9XLFz3YpKmbK2/dcgk39WvDm8v28NQXWynU8XGUUg6gQV8XWveEmz6FycsgrB/88Iwt8H9+HfLOX0vv6iL8c1wP7hnenk/XHuTe2Qn6wHGlVI1p0Nel0Evgljlw1w/Qujcs/YutDX/125B/FrANmTB1ZBeevrori7Yc5c7/rudMrj6aUClVfRr0VgiLgVvnw52LbdffL34CXusNa6f9Nub9XYMj+c/1vViz7wS3TF/Diaw8a2tWSjVYGvRWCo+F276yXYMf0B6+nQpvXALrZ0JBHuOjw3hvUjQ7jmZy/bu/kJJx1uqKlVINkAZ9fRAxyBb2v/8S/MJg4UO2wI//gCs6+/PRH/qTejqXCe/8wp7UTKurVUo1MBUGvYi0EZFlIrJNRBJF5P5S1pkqIhvtr60iUigi/vZlSSKyxb7M4gfB1mMitksx71xsezi5T0v4+j54I5p+Gd/y2eQY8gsN17+7mk2HMqyuVinVgFT4cHARaQ20NsYkiIgvEA+MNcZsK2P9a4EHjTGX2d8nATHGmOOVLapePBzcasbA7iWw7Dk4sgn8Izke/SDjf2pNWlYh026NYVDHQKurVErVEzV6OLgx5ogxJsE+nQlsB0LL2eQmYHZ1ClXFiECnkRC3AiZ+Cu7eBC69lx88n+BWnw3c+d81LNpS8fNrlVKqwjP6C1YWiQBWAt2NMRfd4ikiXkAy0MEYc8I+bz9wEjDAe8aYaWXsOw6IAwgPD48+cOBA1X4TZ1dUBDu+tg2nkLadg65teT5nLAOvvYNbYttZXZ1SymLlndFXOuhFxAdYATxnjJlfxjo3ApOMMdcWmxdqjEkRkZbAUuBeY8zK8j5Lm27KUVQE2xZQtOxfuKTvZntROPt73MdV4/+AuGjfulKNVY2abuw7cAfmAZ+UFfJ2EynRbGOMSbH/TAUWAP0q85mqDC4u0H08LvespWDsewR4FDE68RGOvBRL0Y5vbW37SilVTGWuuhFgJrDdGPNyOev5AUOBL4vN87Z34CIi3sAIYGtNi1aAiytuvScS+OhGvoh4mvwzJ3H5bCJF0y+D3d9r4CulflOZM/qBwK3AZcUuoRwtIneLyN3F1hsHLDHGZBWbFwz8JCKbgHXAQmPMdw6rXuHi5s6Y2x5h4ZCveDR/MieOpcAn42HmCNjzQ4VPu1JKOb8qdcbWFW2jr56P1xzg2S838nDQeiabebhkHoZmodBtDESNg9AYW9OPUsrplNdG71bXxajaMym2Lc293Hnwf+58Ezicj686gt++hbB+Bqx5G5qFQdRY6DbWNt6OiNUlK6XqgJ7RO6FVu9OY8lE8gT5NmXV7DB2aFcHObyFxgb05Jx/82tjP9H9nG1VTQ1+pBs0hl1fWJQ36mtt4KIO7PlhPbn4Rr9/Uh+FdWtoWnM04H/p7f7SHfjhE2Zt3QjT0lWqINOgbqZSMs8R9uIFtR07z6Mgu3D00Eike4mdPlgj9Amgebgv8bmMhpI+GvlINhAZ9I3Y2r5CpczfxzeYjjOkdwgvje+Lh7nrxitknYOciW+jvW24P/ba20I8aB617aegrVY9p0DdyxhjeXr6Xl5bspHuIH9N+H01rP8+yN8g+ATsWng99Uwgt2tlDfyy06qmhr1Q9o0GvAPh+2zHu/+xXPJu48d6t0US3bVHxRtknYMc39tBfYQt9/8jzZ/rB3TX0laoHNOjVb3Ydy2Tyhxs4kpHDP8Z154aYNpXfOCvdNrBa4gLYv8oW+gEdbO35UeMgOEpDXymLaNCrC2Rk53HPpwn8vCedOwe248nRXXBzreKNVFnHYbs99JNWgSmCgI7nm3dadtPQV6oOadCrixQUFvHcou28/3MSgzsG8sZNfWju1aR6OzuTdv5MP+knW+gHdjrfvNOyq2OLV0pdRINelWnO+kM89cUWQpp7MuP3MXQM9q3ZDs+kwvavIPELW+hjwL89RAyENrG2B6L7R+rZvlIOpkGvyhV/4ARTPkogJ7+QV2/szRXdgh2z48xjttDfvRQOrYWcDNt87yBo0x/CB9iCv1VPcKvmXxNKKUCDXlXC4YyzTPkonq2HT/HIiM78aVj7C2+uqqmiIji+Ew6usb0OrYGTSbZlbp4QGm0L/fBYCOsLns0d99lKNQIa9KpSzuYV8ui8zXy96TDX9grh3+N74tmklJurHCXzqD3018LB1XBks+1KHsTWmRtuP+tv0992x6429yhVJg16VWnGGN5ZsZcXF+8kKqQZ026NIaR5OTdXOVJeFiRvOB/8h9ZDXqZtmW/IhcEf3B1cdfBVpc7RoFdV9sP2Y9z/2UY83F14d1I0MRH+dV9EUSEcS7QHv73J53SybVkTH9tQy+c6eMNioGkNO5KVasA06FW17EnN5K4PNpCScZZ/jO3OjX3DrS4JMg5dGPzHtgIGxAVa9Tgf/OGx0CzE6mqVqjMa9KraTmXn8+fZCazafZzbL43g6au7Vv3mqtqUcwqS18PBtbYO3uQNkJ9tW+YXbg99e5NPUFd9wpZyWhr0qkYKCov417c7mPnTfgZ2CODNmy6hhXc9vRyyMB+Objl/Zc/BNXDmmG2Za1No0dY2QFuLCPC3/2zRzjbfvY76IpSqBTUKehFpA3yI7UHfBphmjHmtxDrDgC+B/fZZ840xz9qXjQJeA1yBGcaY5ysqWIO+fvp8wyGeWrCVVn4ezLgthk41vbmqLhhju4zz4BpITYQT++HkATi5H/LOXLiuT6sS4R9x/r13kF71o+q1mgZ9a6C1MSZBRHyBeGCsMWZbsXWGAY8YY64psa0rsAu4EkgG1gM3Fd+2NBr09Vf8gZPc/XE82bkFvHJjb0ZEtbK6pOoxBrLT7cGfZH/Zp0/sh8zDF67v7l3ir4AI28HAv53tsYx6w5eyWI0eDm6MOQIcsU9nish2IBQoN6zt+gF7jDH77IV8Boyp5LaqHopu24Kv/jyQuA/jifsonkdGdOKe4R0ce3NVXRAB70Dbq03fi5fn50DGgfPBf+5AkL4H9nwPBTnF9uUCzULPHwBK/lXgZcEVS0oVU6ULkUUkAugDrC1l8QAR2QQcxnZ2n4jtgHCo2DrJQP8y9h0HxAGEh9eDqztUmVr7efL53QN4bN5mXlqyi+1HM3lxQk+8mjjRde3uHhDU2fYqqajI1u5f8q+Ak0mw6zvISrtwfQ+/C4O/WSj4BIF3S/BpaWsW8vDTpiFVayr9P1NEfIB5wAPGmNMlFicAbY0xZ0RkNPAF0LEqhRhjpgHTwNZ0U5VtVd3zcHfl1Rt707V1M174bgf707KYflsMoXV1c5WVXFygWWvbq+2Ai5fnnim9OejoFtuTu4ryL97GtYkt8L2D7OHf8vzBwDvowgODp79ePaSqpFJBLyLu2EL+E2PM/JLLiwe/MWaRiLwtIoFAClD8yRZh9nnKCYgIdw9tT+dgX+6b/SvXvfET70yKpl+7Rt5U0dQHWnW3vUoqKrT1DZxJhaxU2xDPWWnFplNtQ0Mc3WKbX1Rw8T7E1d7s1NL289xfBaUdILwDwdW99n9nVa9VpjNWgA+AE8aYB8pYpxVwzBhjRKQfMBdoi+1Km13A5dgCfj1ws71Zp0zaGdvw7Ek9w+QPN5B8Mptnx3Tnpn7a/FZjRUW2ET+z0kocGFLt7+0HiXPzivcbFOfpf/HBwDsQmjaDJl7g7gVNvG2Xl7p7lzLPS5uVGoAadcYCA4FbgS0istE+70kgHMAY8y4wAfijiBQAZ4GJxnYEKRCRPwOLsYX+rIpCXjVMHVr68MWfBnLvZ7/yxPwtbD9ymr9c0w33+nRzVUPj4mLryPXyL72voDhjIDfzwoNC8YPAuQNDSoLtZ8lLSyvifi78vYpNe5cyz6vYwaL4gaO0efZ9uDbRA0kt0xumlEMVFBbxwnc7mL5qPwMiA3jrlkvwr683VzVm+WdtfQn5WZCXbXv/23Rp8+yvC5YXn5dtG5QuPxsK86pYjNgPAJ62IavdPUpMe4Gbx8XruNnfXzDtaV/Xq4z5nuBSiyOyWkjvjFV1bl58Mk8s2EJws6ZM/30MXVo1s7okVVcKC4odBLLsB4xiB4ILDhJZtian/LO21wXTZ22XueZn2+cXn862PbKyOlybXHyQKH4fhDGAsd0eapthn1d82pRYt+Ty8tYtZ7/eAXD3T9X6tWradKNUlY2PDiMyyJspH8Uz7q1feHJ0FybFtm1419urqnN1A9dm4FGLB3djbMNdXHQwOHv+QJCfU2L6bIkDSrH5BbmAFGtCOjdtf1/83+25+eWuK9VYF2jq59jv6dyn6hm9qk3HTufwyOebWLX7OIM7BvLC+J51N769Uo1IeWf02lOmalVwMw8+vLMf/xjbnQ1JJxn56krmxSdTH08wlHJWGvSq1okIk2Lb8t0Dg+kc7MvDn29iykfxHD+Ta3VpSjUKGvSqzrQN8OZ/UwbwxFVdWL4zjZGvrOS7rUetLkspp6dBr+qUq4swZWh7vr53EK38PLj743ge+t9GTp0tZVgApZRDaNArS3Ru5cuCPw3kvss68OWmw4x6dSWrdqdVvKFSqso06JVlmri58NCIzsz/46V4NXHl1pnr+MsXW8nOK2V8F6VUtWnQK8v1atOchfcN5s6B7fhozQFGv7aK+AMnrC5LKaehQa/qBQ93V/56bTdmT46loMhw/buref7bHeQWFFpdmlINnga9qlcGtA/guweGcENMG95dsZcxb/5M4uFTVpelVIOmQa/qHZ+mbjw/viezbo8hPSuPsW/9zJs/7qagsJpjmyjVyGnQq3rrsi7BLHlgCCOjWvHSkl1MeHc1e9OqOLyuUkqDXtVvLbyb8ObNl/DGTX1ISs/i6tdX8f7P+ykq0iEUlKosDXrVIFzbK4QlDwxhQGQAz3y9jVtmrCX5ZLbVZSnVIGjQqwajZTMPZt3el+d/14PNyRmMenUVczYc0gHSlKqABr1qUESEif3C+e6BIUSFNOPRuZuZ/OEGUjPLeF6qUkqDXjVMbfy9mD05lqev7srK3ccZ+cpKFm05YnVZStVLFQa9iLQRkWUisk1EEkXk/lLWuUVENovIFhH5RUR6FVuWZJ+/UUT0aSLKYVxchLsGR7LovkG08ffiT58kcP9nv5KRXdVnlirl3CpzRl8APGyM6QbEAveISLcS6+wHhhpjegB/B6aVWD7cGNO7rKefKFUTHVr6Mu+Pl/LQlZ1YuPkII19dyfKdqVaXpVS9UWHQG2OOGGMS7NOZwHYgtMQ6vxhjTtrfrgHCHF2oUuVxd3Xhvss78sU9A/HzdOf299fz5IItZOXqAGlKVamNXkQigD7A2nJW+wPwbbH3BlgiIvEiElfOvuNEZIOIbEhL0+FqVfV0D/Xjqz8PYsqQSGavO8io11aybr8OkKYat0o/HFxEfIAVwHPGmPllrDMceBsYZIxJt88LNcakiEhLYClwrzFmZXmfpQ8HV46wPukED8/ZxKGT2UweHMlDV3bCw93V6rKUqhU1fji4iLgD84BPygn5nsAMYMy5kAcwxqTYf6YCC4B+VStfqerpG+HPt/cP5uZ+4UxbuY+rXlvFksSjet29anQqc9WNADOB7caYl8tYJxyYD9xqjNlVbL63iPiemwZGAFsdUbhSleHd1I3nxvXgwzv74SIQ91E8E6etYUuyjoipGo8Km25EZBCwCtgCnBs+8EkgHMAY866IzADGAwfsywuMMTEiEontLB7ADfjUGPNcRUVp042qDfmFRXy2/hCvLt1FelYe4/qEMnVkZ0Kae1pdmlI1Vl7TTaXb6OuSBr2qTadz8nln+V5m/rQfAe4a3I4/DuuAT1M3q0tTqtpq3EavlDNp5uHOY6O68OPDQxnVvRVvLdvLsBeX8cnaAzrmvXJKGvSq0Qpr4cVrE/vwxT0DaRfozVMLtnLVa6tYtjNVO2yVU9GgV41e7zbNmTNlAO9Oiia/sIg73l/PrTPXse3waatLU8ohNOiVwjYq5qjurVjy4FD+ek03th4+xdVvrOLRuZs4dlpHxlQNm3bGKlWKU9n5vPHjbj5YnYSbiwtThkYSNyQSrybaYavqJ+2MVaqK/Lzcefqabnz/0FCGdwni1e93M/yl5czZcIhCfYyhamA06JUqR9sAb96+JZp5fxxASHNPHp27mWve+Imfdh+3ujSlKk2DXqlKiG7rz/w/XsobN/UhMyefSTPXcsf769h9LNPq0pSqkAa9UpUkIlzbK4TvHxrKk6O7sOHASUa9toqnFmzh+Jlcq8tTqkwa9EpVkYe7K3FD2rNi6nBujW3L/9YfYtiLy3lr2R5y8gutLk+pi2jQK1VN/t5N+Nt1USx+cAgD2gfw4uKdXPbSchb8mkyRdtiqekSDXqkaah/kw/TfxzB7ciz+Pk148H+bGPv2z6zdl17xxkrVAQ16pRxkQPsAvrpnEK/c2Iu0zFxunLaGuA83sC/tjNWlqUZOg14pB3JxEcb1CWPZI8OYOrIzP+85zohXVvK3rxI5mZVndXmqkdKgV6oWeLi7cs/wDiyfOpwb+rbhw9VJDHlxGdNW7iW3QDtsVd3SIRCUqgO7jmXyz0XbWb4zjZa+Tbl9YAS39G+Ln6e71aUpJ6EPHlGqnvhlz3HeWbGXVbuP493ElRv7hnPnoAjCWnhZXZpq4DTolapnEg+fYsaq/Xy96TAGuLpHa+KGRNI91M/q0lQDVaNBzUSkjYgsE5FtIpIoIveXso6IyOsiskdENovIJcWW3SYiu+2v22r2qyjlHKJC/Hjlxt6sfHQ4dw6M4McdqVzzxk/cMmMNy/XBJ8rBKvNw8NZAa2NMgoj4AvHAWGPMtmLrjAbuBUYD/YHXjDH9RcQf2ADEAMa+bbQx5mR5n6ln9KqxOZ2Tz+y1B3n/5ySOns6hc7Avk4dEcl2vEJq46TUTqmI1OqM3xhwxxiTYpzOB7UBoidXGAB8amzVAc/sBYiSw1Bhzwh7uS4FRNfhdlHJKzTzcmTK0PSsfHc5/ru+FCDzy+SYG//tH3l2xl1Nn860uUTVgVXqKgohEAH2AtSUWhQKHir1Pts8ra75SqhRN3FwYHx3G7y4JZeXu40xfuY/nv93Bmz/uYWLfNtw5qB0hzT2tLlM1MJUOehHxAeYBDxhjHP4wTRGJA+IAwsPDHb17pRoUEWFopyCGdgpia8oppq/ax/u/JPHfX5K4pmdrJg+JJCpEO25V5VSq8U9E3LGF/CfGmPmlrJICtCn2Psw+r6z5FzHGTDPGxBhjYoKCgipTllKNQvdQP16b2IeVjw7ntksjWLrtGFe//hOTZqxl5a407bhVFapMZ6wAHwAnjDEPlLHO1cCfOd8Z+7oxpp+9MzYeOHcVTgK2ztgT5X2mdsYqVbZTZ/P5dO1B3v95P6mZuXRp5UvckEiu6akdt41Zja6jF5FBwCpgC1Bkn/0kEA5gjHnXfjB4E1tHazZwhzFmg337O+3rAzxnjHm/ooI16JWqWF5BEV9uTGH6qn3sOnaGVs08uGNgBDf1D6eZh95x29joDVNKOTFjDMt3pTF95T5+2ZuOT1M3bu4fzu2XRmjHbSOiQa9UI7El+RTTVu1j0ZYjCHBtrxAmD46kW0gzq0tTtUyDXqlG5tCJbN7/OYnP1h8kO6+QwR0DiRsSyaAOgdhaWpWz0aBXqpE6lZ3Px2sP8N9fkkjLzKVr62bEDWnHNT1DcHfVjltnokGvVCOXW1DIlxsPM33lPnannqG1nwc39Qvnd5eE6siZTkKDXikFQFGRYcWuNGb8tI+f96QjApe2D2BCdBijolrj2cTV6hJVNWnQK6UucuhENvMTUpibcIhDJ87i09SNa3q2ZkJ0GNFtW2hbfgOjQa+UKlNRkWFd0gnmxiezaMsRsvMKaRfozQT7mDut/fQSzYZAg14pVSlZuQUs2nKEufHJrN1/AhEY1CGQ62PaMKJbMB7u2rRTX2nQK6Wq7EB6FvMSUpgXn0xKxll8Pdy4tlcI10eH0btNc23aqWc06JVS1VZUZFizL53P45P5dusRcvKL6NDShwnRYYzrE0pwMw+rS1Ro0CulHCQzJ59FW47w+YZkNhw4iYvA0E5BTIhuwxXdWtLUTZt2rKJBr5RyuP3Hs5gbf4j5CSkcOZWDn6c7Y3qHMCE6jB6hftq0U8c06JVStaawyPDznuPMjU9mceJRcguK6Bzsy4ToMMb2CSXIt6nVJTYKGvRKqTpx6mw+32w+zNz4ZH49mIGrizC8cxATosO4rEuwjpdfizTolVJ1bk9qJnPjU5ifkExqZi4tvNwZ0zuU62PC9DGItUCDXillmYLCIlbZm3aWJh4jr7CIrq2b2Zp2eocQ4KNNO46gQa+UqhcysvP4etNhPo9PZnPyKdxchNjIAEZGBXNFt2C9C7cGNOiVUvXOzqOZLPg1hSWJR9l3PAuAXmF+jIhqxYhuwXRo6aNX7lSBBr1Sql7bk3qGJduOsiTxGBsPZQDQLtCbEd2CGREVTJ82LXBx0dAvT00fDj4LuAZINcZ0L2X5VOAW+1s3oCsQZIw5ISJJQCZQCBSUVURJGvRKNV7HTuewdNsxFiceZfXedAqKDIE+TbnSHvqXtg/QG7NKUdOgHwKcAT4sLehLrHst8KAx5jL7+yQgxhhzvCoFa9ArpcB2uebynaks2XaM5TtSycorxLuJK8O6tGREt2CGd2lJMw93q8usF8oLereKNjbGrBSRiEp+1k3A7CrUppRSZbLdbRvKmN6h5BYU8svedJYkHmPptmMs3HwEd1dbZ+6IqFZc2TWYVn467k5pKtVGbw/6b8o7oxcRLyAZ6GCMOWGftx84CRjgPWPMtHK2jwPiAMLDw6MPHDhQhV9DKdWYFBUZfj10kiWJtiaepPRsAHq1ac7IqGBGdGtFh5Y+FldZt2rcGVvJoL8RmGSMubbYvFBjTIqItASWAvcaY1ZW9HnadKOUqixjjL0z9xhLEo+yKfkUAJFB3ozo1ooRUcH0Dmvu9J25NWq6qYKJlGi2Mcak2H+misgCoB9QYdArpVRliQgdg33pGOzLPcM7cOTUWZZuO8aSxGPMWLWPd1fsJcjX3pnbLZhL2wc2uqEYHHJGLyJ+wH6gjTEmyz7PG3AxxmTap5cCzxpjvqvo8/SMXinlCKey81m2M5Ul246yfGca2XmF+DZ1+60zd1jnIHydpDO3Rmf0IjIbGAYEikgy8H+AO4Ax5l37auOAJedC3i4YWGC/4cEN+LQyIa+UUo7i5+XO2D6hjO0TSk5+Ib/sPf5bZ+7Xmw7j7ipc2j6QK7oFM7B9AO0CvZ3yJi29YUop1egUFhkSDp5kSeJRFice4+AJW2duq2YexEb6M6B9AAMiA2nj79lggl/vjFVKqTIYY9h3PIvVe9NZvS+dtfvSOX4mD4DQ5p7ERgbYgr99AKHN6+9YPBr0SilVScYYdqeesQX/3nTW7E8nIzsfgHB/LwYUC/769LxcDXqllKqmoiLDjqOZrNl3/oz/dE4BAJGB3sS2D2BAZACxkQGWPk1Lg14ppRyksMiw/cjp35p61u0/wZlcW/B3bOljb98PoH9kAP7eTeqsLg16pZSqJQWFRWw9fD74NySdIDuvEIAurXzPB3+7APy8au9STg16pZSqI/mFRWxOzigW/CfJLShCBKJCmhHbzta+36+dv0Ov4degV0opi+QWFLLxYAar99k6d389mEFeYREuAj1C/X5r4+8b4Y930+oPVqBBr5RS9UROfiEJB0+yxn7Gv/FQBvmFBjcX4ZLwFsyOi8W1GuPy1NVYN0oppSrg4e7Kpe0DubR9IADZeQXEHzjJ6r3pnMjKq1bIV0SDXimlLOTVxI3BHYMY3DGo1j6jcQ3hppRSjZAGvVJKOTkNeqWUcnIa9Eop5eQ06JVSyslp0CullJPToFdKKSenQa+UUk6uXg6BICJpwIFqbh4IHHdgOQ2ZfhcX0u/jQvp9nOcM30VbY0ypd13Vy6CvCRHZUNZ4D42NfhcX0u/jQvp9nOfs34U23SillJPToFdKKSfnjEE/zeoC6hH9Li6k38eF9Ps4z6m/C6dro1dKKXUhZzyjV0opVYwGvVJKOTmnCXoRGSUiO0Vkj4g8bnU9VhKRNiKyTES2iUiiiNxvdU1WExFXEflVRL6xuhariUhzEZkrIjtEZLuIDLC6JiuJyIP2/ydbRWS2iHhYXZOjOUXQi4gr8BZwFdANuElEullblaUKgIeNMd2AWOCeRv59ANwPbLe6iHriNeA7Y0wXoBeN+HsRkVDgPiDGGNMdcAUmWluV4zlF0AP9gD3GmH3GmDzgM2CMxTVZxhhzxBiTYJ/OxPYfOdTaqqwjImHA1cAMq2uxmoj4AUOAmQDGmDxjTIalRVnPDfAUETfACzhscT0O5yxBHwocKvY+mUYcbMWJSATQB1hrcSlWehV4FCiyuI76oB2QBrxvb8qaISLeVhdlFWNMCvAScBA4ApwyxiyxtirHc5agV6UQER9gHvCAMea01fVYQUSuAVKNMfFW11JPuAGXAO8YY/oAWUCj7dMSkRbY/vpvB4QA3iIyydqqHM9Zgj4FaFPsfZh9XqMlIu7YQv4TY8x8q+ux0EDgOhFJwtakd5mIfGxtSZZKBpKNMef+wpuLLfgbqyuA/caYNGNMPjAfuNTimhzOWYJ+PdBRRNqJSBNsnSlfWVyTZUREsLXBbjfGvGx1PVYyxjxhjAkzxkRg+3fxozHG6c7YKssYcxQ4JCKd7bMuB7ZZWJLVDgKxIuJl/39zOU7YOe1mdQGOYIwpEJE/A4ux9ZrPMsYkWlyWlQYCtwJbRGSjfd6TxphF1pWk6pF7gU/sJ0X7gDssrscyxpi1IjIXSMB2tdqvOOFwCDoEglJKOTlnabpRSilVBg16pZRychr0Sinl5DTolVLKyWnQK6WUk9OgV0opJ6dBr5RSTu7/ATZqfhcAK9gmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adam은 적응적 학습률 알고리즘이기에 학습률 파라미터의 튜닝의 필요성이 적습니다. - 핸즈온 머신러닝 441p\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=1)\n",
    "#reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, min_lr=1e-5, min_delta=0.05)\n",
    "\n",
    "\n",
    "\n",
    "model = create_model()\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "history = model.fit(dataset, \n",
    "                    validation_data = (te_src_input, te_tgt_input),\n",
    "                    callbacks=[es],\n",
    "                    epochs=10)\n",
    "\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "excessive-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./model/saved_model_dropout0_2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-absence",
   "metadata": {},
   "source": [
    "## 8. 학습된 모델 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "acoustic-nicholas",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 7639.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<start> i love <end>'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_setence(init_setence, max_len = 20):\n",
    "    init_sentence = [init_setence.split()]\n",
    "    test_tensor = vectorization(init_sentence, vocab, te_src_input.shape[1])\n",
    "\n",
    "    while True:\n",
    "        # 1\n",
    "        predict = model.predict(test_tensor)\n",
    "        # 2\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        # 3 \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 4\n",
    "        if predict_word.numpy()[0] == word_index[\"<end>\"]: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    pred_sentence = test_tensor.numpy()[0]\n",
    "    for ind, i in enumerate(pred_sentence):\n",
    "        if i != 0:\n",
    "            tmp = pred_sentence[ind:]\n",
    "            break\n",
    "\n",
    "    return \" \".join([index_word[index] for index in tmp])\n",
    "\n",
    "generate_setence(\"<start> i love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-philosophy",
   "metadata": {},
   "source": [
    "## 모델 성능 개선을 위한 노력\n",
    "- 하이퍼 파라미터 조절\n",
    "    1. vocab 사이즈 조절\n",
    "    2. embedding 사이즈 조절\n",
    "    3. hidden state 크기 조절\n",
    "- 텍스트 데이터 전처리\n",
    "- 외부 모델 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-little",
   "metadata": {},
   "source": [
    "## 하이퍼 파라미터 조절"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-merit",
   "metadata": {},
   "source": [
    "vocab size를 20,000 embedding size를 256 hidden state 크기를 1024로 하여 단순히 하이퍼 파라미터를 크게 한다고 좋은게 아니라고 느꼈습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-colleague",
   "metadata": {},
   "source": [
    "sentence: 10000  \n",
    "vocab_size: 31973 embedding_size: 256 hidden_size: 1024 dropout_rate: 0.2 loss: 3.5306 - val_loss: 3.8973  \n",
    "\n",
    "vocab_size: 31973 embedding_size: 256 hidden_size: 1024 dropout_rate: 0.05 loss: 3.5625 - val_loss: 3.9262  \n",
    "\n",
    "vocab_size: 31973 embedding_size: 256 hidden_size: 1024 dropout_rate: 0.5 loss: 3.6373 - val_loss: 3.8414  \n",
    "\n",
    "vocab_size: 31973 embedding_size: 256 hidden_size: 1024 dropout_rate: 0.8 loss: 3.8938 - val_loss: 3.8881 다시 val_loss가 상승함  \n",
    "\n",
    "vocab_size: 31973 embedding_size: 256 hidden_size: 1024 dropout_rate: 0.5 loss: 3.3754 - val_loss: 4.2197 batchnormalization  \n",
    "\n",
    "vocab_size: 31973 embedding_size: 256 hidden_size: 1024 dropout_rate: 0.5 loss: 3.5693 - val_loss: 3.8093 ReduceLROnPlateau  \n",
    "\n",
    "vocab_size: 31973 embedding_size: 256 hidden_size: 1024 dropout_rate: 0.5 loss: 3.5812 - val_loss: 3.8101 ReduceLROnPlateau batchnormalization 1개 epoch 9   \n",
    "\n",
    "vocab_size: 31973 embedding_size: 256 hidden_size: 1024 dropout_rate: 0.5 loss: 3.6421 - val_loss: 3.8326 ReduceLROnPlateau batchnormalization 2개   \n",
    "\n",
    "\n",
    "sentence: full  \n",
    "vocab_size: 31973 embedding_size: 256 hidden_size: 1024 dropout_rate: 0.5 loss: 3.5812 - val_loss: 3.8101 ReduceLROnPlateau batchnormalization 2개 \n",
    "\n",
    "sentence: 20000  \n",
    "vocab_size: 31973 embedding_size: 256 hidden_size: 1024 dropout_rate: 0.5 loss: 3.5812 - val_loss: 3.8101 ReduceLROnPlateau batchnormalization 2개 batch_size: 64\n",
    "\n",
    "vocab_size: 31973 embedding_size: 256 hidden_size: 1024 dropout_rate: 0.5 loss: 3.5812 - val_loss: 3.8101 ReduceLROnPlateau batchnormalization 1개 batch_size: 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-shooting",
   "metadata": {},
   "source": [
    "loss: 1.9850 - val_loss: 3.2193"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-mercury",
   "metadata": {},
   "source": [
    "## 텍스트 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-rapid",
   "metadata": {},
   "source": [
    "관사 a, an, the를 제외한 길이가 1인 단어는 모두 제거하기\n",
    "\n",
    "중복되는 문장 제거하기는 오히려 성능의 저하가 발생하여 중복제거는 안하는 것이 좋다는 것을 알았습니다.  \n",
    "중복 제거 전 : loss: 3.5905 - val_loss: 3.8269  \n",
    "중복 제거 후 : loss: 3.9458 - val_loss: 4.1933\n",
    "\n",
    "배치사이즈를 적절하게 줄여야지 모델의 학습이 제대로 이루어져서 loss값이 감소하는 것을 알았습니다.\n",
    "- why? 배치사이즈를 줄임으로써 그래디언트가 갱신되는 횟수가 증가하여 수렴지점으로 더 쉽게 지나가기 때문이지 않을까?\n",
    "\n",
    "unknown 토큰을 추가하자 train loss값이 착실하게 감소하게 되었습니다.\n",
    "\n",
    "start 토큰과 end토큰을 제거하고 하는것이 더 학습이 잘됩니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
