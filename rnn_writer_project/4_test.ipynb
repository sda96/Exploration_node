{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "entertaining-donor",
   "metadata": {},
   "source": [
    "## 1. 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "virtual-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-armenia",
   "metadata": {},
   "source": [
    "## 2. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "continent-proportion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기 : 187088\n"
     ]
    }
   ],
   "source": [
    "txt_list = glob.glob(\"./data/lyrics/*\")\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "for file in txt_list:\n",
    "    with open(file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "        \n",
    "print(f\"데이터 크기 : {len(raw_corpus)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "naughty-showcase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187088"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-palmer",
   "metadata": {},
   "source": [
    "## 3. 텍스트 전처리 - 소문자화, 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "periodic-literacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kdnuggets.com/2019/04/text-preprocessing-nlp-machine-learning.html\n",
    "def text_preprocessing(corpus):\n",
    "    corpus = corpus.lower()\n",
    "    corpus = re.sub('[^a-z?\\'!]', ' ', corpus)\n",
    "    \n",
    "    # 혼자 있는 따옴표 제거\n",
    "    corpus = re.sub(' \\' ', ' ', corpus)\n",
    "\n",
    "    \n",
    "    # 혼자있는 자음 제거\n",
    "    tmp = None\n",
    "    while tmp != corpus:\n",
    "        tmp = corpus\n",
    "        corpus = re.sub(\" [xobgnerclfpkyvjhwzqstmd] \", ' ', corpus)\n",
    "    \n",
    "    corpus = re.sub(\"^[u] \", \"you\", corpus)\n",
    "    corpus = re.sub(\" [u]$\", \"you\", corpus)\n",
    "    corpus = re.sub(\"[ ]+\", ' ', corpus)\n",
    "    corpus = corpus.strip()\n",
    "    \n",
    "    \n",
    "    # u를 you로 전환\n",
    "    # corpus = re.sub(\"^<start> u \", '<start> you ', corpus)\n",
    "    # corpus = re.sub(\" u <end>$\", ' you <end>', corpus)\n",
    "    corpus = '<start> ' + corpus + ' <end>'\n",
    "    corpus = corpus.strip()\n",
    "    return corpus\n",
    "\n",
    "# 전처리 적용\n",
    "tmp = list(map(text_preprocessing, raw_corpus))\n",
    "# 전처리 적용 후 단어가 없는 경우 제거\n",
    "clean_corpus = []\n",
    "for i in tmp:\n",
    "    if len(i.split(\" \")) > 0:\n",
    "        clean_corpus += [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "processed-sixth",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기 : 187088\n"
     ]
    }
   ],
   "source": [
    "print(f\"데이터 크기 : {len(clean_corpus)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "thorough-management",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<start> i hear you callin' here i come baby <end>\",\n",
       " '<start> to save you oh oh <end>',\n",
       " \"<start> baby no more stallin' <end>\",\n",
       " '<start> these hands have been longing to touch you baby <end>',\n",
       " \"<start> and now that you've come around to seein' it my way <end>\",\n",
       " \"<start> you won't regret it baby and you surely won't forget it baby <end>\",\n",
       " \"<start> it's unbelieveable how your body's calling for me <end>\",\n",
       " \"<start> i can just hear it callin' callin' for me my body's callin' for you <end>\",\n",
       " \"<start> my body's callin' for you <end>\",\n",
       " \"<start> my body's callin' for you <end>\",\n",
       " \"<start> my body's callin' for you tell me what's your desire <end>\",\n",
       " '<start> baby your wish is my deal oh yes it is baby <end>',\n",
       " '<start> let me take you higher <end>',\n",
       " '<start> show you how you should feel baby <end>',\n",
       " '<start> oh so we speak now and forever hold your body <end>',\n",
       " '<start> whatever it is you want from me baby <end>',\n",
       " \"<start> you see you don't have to say nothing <end>\",\n",
       " '<start> knowing your body wants something <end>',\n",
       " \"<start> and it's easy for me to see <end>\",\n",
       " \"<start> that your body's callin' for me my body's callin' for you <end>\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_corpus[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-chester",
   "metadata": {},
   "source": [
    "## 4. 텍스트 전처리 - 토큰화, 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "minute-member",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_corpus = list(map(lambda x : x.split(),clean_corpus))\n",
    "\n",
    "tmp = defaultdict()\n",
    "for corpus in split_corpus:\n",
    "    for word in corpus:\n",
    "        if word not in tmp:\n",
    "            tmp[word] = corpus.count(word)\n",
    "        else:\n",
    "            tmp[word] += corpus.count(word)\n",
    "\n",
    "tmp = dict(tmp)\n",
    "word_count = sorted(tmp.items(), key = lambda x : x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "perfect-assist",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187088/187088 [00:00<00:00, 265856.06it/s]\n"
     ]
    }
   ],
   "source": [
    "word_index = dict()\n",
    "index_word = dict()\n",
    "for ind, i in enumerate(word_count):\n",
    "    word_index[i[0]] = ind + 1\n",
    "    index_word[ind] = i[0]\n",
    "\n",
    "word_index[\"<pad>\"] = 0\n",
    "index_word[0] = \"<pad>\"\n",
    "\n",
    "vector_corpus = []\n",
    "for corpus in tqdm(split_corpus):\n",
    "    tmp = []\n",
    "    if len(corpus) < 15:\n",
    "        for i in corpus:\n",
    "                tmp += [word_index[i]]\n",
    "        vector_corpus += [tmp]\n",
    "\n",
    "vector_corpus = tf.keras.preprocessing.sequence.pad_sequences(vector_corpus, padding=\"pre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "approved-deviation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,    54,    37,     2],\n",
       "       [    0,     0,     0, ...,    13,    13,     2],\n",
       "       [    0,     0,     0, ...,    89, 10458,     2],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,    33,   116,     2],\n",
       "       [    0,     0,     0, ...,    10,   152,     2],\n",
       "       [    1,     6,    41, ...,   315,   315,     2]], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "direct-armenia",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i, j in word_count:\n",
    "#     if len(i) == 1:\n",
    "#         print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "first-fabric",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # u, x 만 있는 단어 찾기\n",
    "# tmp = list(map(lambda x : len(re.findall(\" q \", x)), clean_corpus))\n",
    "# for i in range(len(clean_corpus)):\n",
    "#     if tmp[i] != 0:\n",
    "#         print(i, clean_corpus[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "representative-migration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_corpus\n",
    "\n",
    "# from gensim.models import Word2Vec\n",
    "# word2vec_model = Word2Vec(vector_size = 300, window=5, min_count = 1, workers = 2)\n",
    "# word2vec_model.build_vocab(split_corpus)\n",
    "# word2vec_model.intersect_word2vec_format('./word2vec/GoogleNews-vectors-negative300.bin', lockf=1.0, binary=True)\n",
    "\n",
    "# word2vev = Word2Vec(split_corpus)\n",
    "\n",
    "# word2vev.wv\n",
    "\n",
    "# tmp = []\n",
    "# for corpus in split_corpus[:10]:\n",
    "#     tmp += [list(map(lambda x: word2vev.wv[x], corpus))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hydraulic-weekly",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 갯수 : 169998\n",
      "문장 길이 : 14\n",
      "텍스트에서 변환된 시퀀스 가장 큰 인덱스값 : 31975\n"
     ]
    }
   ],
   "source": [
    "print(f\"문장 갯수 : {vector_corpus.shape[0]}\\n문장 길이 : {vector_corpus.shape[1]}\")\n",
    "print(f\"텍스트에서 변환된 시퀀스 가장 큰 인덱스값 : {np.max(vector_corpus)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-adolescent",
   "metadata": {},
   "source": [
    "## 5. 학습데이터셋, 테스트데이터셋 분리 및 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "false-bulletin",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 305\n",
    "np.random.seed(seed)\n",
    "random_index = np.random.choice(range(len(vector_corpus)), 10000)\n",
    "mini_vector_corpus = vector_corpus[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "right-monthly",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_input = mini_vector_corpus[:, :-1]\n",
    "tgt_input = mini_vector_corpus[:, 1:]\n",
    "\n",
    "tr_src_input,te_src_input,tr_tgt_input,te_src_input = train_test_split(src_input,\n",
    "                                                                      tgt_input,\n",
    "                                                                      test_size = 0.2,\n",
    "                                                                      random_state = seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "lightweight-teens",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[    1,   634,     9,    12,     7,   132,  2372,  6973,     5,\n",
       "           889,    76,     7, 24147],\n",
       "        [    0,     0,     0,     0,     0,     0,     1,     4,    31,\n",
       "             3,    82,    46,   564]], dtype=int32),\n",
       " array([[   0,    0,    0,    0,    0,    1,  326,  135, 6818,  391,   53,\n",
       "         3122,    2],\n",
       "        [   0,    0,    0,    0,    0,    0,    1,    4,  703,   10, 6040,\n",
       "         7551,    2]], dtype=int32))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_src_input[:2], te_src_input[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "coated-thread",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 13), (256, 13)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer_size = len(tr_src_input)\n",
    "batch_size = 64\n",
    "steps_per_epoch = len(tr_src_input) // batch_size\n",
    "\n",
    "vocab_size = len(word_count) + 1\n",
    "dataset = tf.data.Dataset.from_tensor_slices((tr_src_input, tr_tgt_input))\n",
    "dataset = dataset.shuffle(buffer_size)\n",
    "dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-number",
   "metadata": {},
   "source": [
    "## 6. 모델 구조 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "painted-burton",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 256\n",
    "hidden_size = 1024\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(src_input.shape[1]))\n",
    "layer = tf.keras.layers.Embedding(vocab_size, embedding_size)(inputs)\n",
    "layer = tf.keras.layers.BatchNormalization()(layer) \n",
    "layer = tf.keras.layers.LSTM(hidden_size, return_sequences=True, kernel_initializer=\"he_normal\")(layer)\n",
    "layer = tf.keras.layers.Dropout(0.5)(layer)\n",
    "\n",
    "layer = tf.keras.layers.BatchNormalization()(layer) \n",
    "layer = tf.keras.layers.LSTM(hidden_size, return_sequences=True, kernel_initializer=\"he_normal\")(layer)\n",
    "layer = tf.keras.layers.Dropout(0.5)(layer)\n",
    "# activation=\"softmax\" \n",
    "layer = tf.keras.layers.BatchNormalization()(layer)\n",
    "outputs = tf.keras.layers.Dense(vocab_size, kernel_initializer=\"he_normal\")(layer)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-array",
   "metadata": {},
   "source": [
    "## 7. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "declared-above",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 181s 572ms/step - loss: 3.9942 - val_loss: 12.1049\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adam은 적응적 학습률 알고리즘이기에 학습률 파라미터의 튜닝의 필요성이 적습니다. - 핸즈온 머신러닝 441p\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=1)\n",
    "# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, min_lr=1e-5, min_delta=0.05)\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "history = model.fit(dataset, \n",
    "                    validation_data = (te_src_input, te_src_input),\n",
    "                    callbacks = [es],\n",
    "                    epochs=1)\n",
    "\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "weird-visiting",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./model/saved_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-electron",
   "metadata": {},
   "source": [
    "## 8. 학습된 모델 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "included-diving",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 단어 하나씩 예측해 문장을 만듭니다\n",
    "    #    1. 입력받은 문장의 텐서를 입력합니다\n",
    "    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n",
    "    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\n",
    "    #    4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다\n",
    "    while True:\n",
    "        # 1\n",
    "        predict = model(test_tensor) \n",
    "        # 2\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        # 3 \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 4\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "biological-constraint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i i i the the the the the <end> '"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-storage",
   "metadata": {},
   "source": [
    "## 모델 성능 개선을 위한 노력\n",
    "- 하이퍼 파라미터 조절\n",
    "    1. vocab 사이즈 조절\n",
    "    2. embedding 사이즈 조절\n",
    "    3. hidden state 크기 조절\n",
    "- 텍스트 데이터 전처리\n",
    "- 외부 모델 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-spokesman",
   "metadata": {},
   "source": [
    "## 하이퍼 파라미터 조절"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-document",
   "metadata": {},
   "source": [
    "vocab size를 20,000 embedding size를 256 hidden state 크기를 1024로 하여 단순히 하이퍼 파라미터를 크게 한다고 좋은게 아니라고 느꼈습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-aquatic",
   "metadata": {},
   "source": [
    "sentence: 10000  \n",
    "vocab_size: 31973 embedding_size: 256 hidden_size: 1024 dropout_rate: 0.2 loss: 3.5306 - val_loss: 3.8973  \n",
    "\n",
    "vocab_size: 31973 embedding_size: 256 hidden_size: 1024 dropout_rate: 0.05 loss: 3.5625 - val_loss: 3.9262  \n",
    "\n",
    "vocab_size: 31973 embedding_size: 256 hidden_size: 1024 dropout_rate: 0.5 loss: 3.6373 - val_loss: 3.8414  \n",
    "\n",
    "vocab_size: 31973 embedding_size: 256 hidden_size: 1024 dropout_rate: 0.8 loss: 3.8938 - val_loss: 3.8881 다시 val_loss가 상승함  \n",
    "\n",
    "vocab_size: 31973 embedding_size: 256 hidden_size: 1024 dropout_rate: 0.5 loss: 3.3754 - val_loss: 4.2197 batchnormalization  \n",
    "\n",
    "vocab_size: 31973 embedding_size: 256 hidden_size: 1024 dropout_rate: 0.5 loss: 3.5693 - val_loss: 3.8093 ReduceLROnPlateau  \n",
    "\n",
    "vocab_size: 31973 embedding_size: 256 hidden_size: 1024 dropout_rate: 0.5 loss: 3.5812 - val_loss: 3.8101 ReduceLROnPlateau batchnormalization 1개 epoch 9   \n",
    "\n",
    "vocab_size: 31973 embedding_size: 256 hidden_size: 1024 dropout_rate: 0.5 loss: 3.6421 - val_loss: 3.8326 ReduceLROnPlateau batchnormalization 2개   \n",
    "\n",
    "\n",
    "sentence: full  \n",
    "vocab_size: 31973 embedding_size: 256 hidden_size: 1024 dropout_rate: 0.5 loss: 3.5812 - val_loss: 3.8101 ReduceLROnPlateau batchnormalization 2개 \n",
    "\n",
    "sentence: 20000  \n",
    "vocab_size: 31973 embedding_size: 256 hidden_size: 1024 dropout_rate: 0.5 loss: 3.5812 - val_loss: 3.8101 ReduceLROnPlateau batchnormalization 2개 batch_size: 64\n",
    "\n",
    "vocab_size: 31973 embedding_size: 256 hidden_size: 1024 dropout_rate: 0.5 loss: 3.5812 - val_loss: 3.8101 ReduceLROnPlateau batchnormalization 1개 batch_size: 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-netscape",
   "metadata": {},
   "source": [
    "## 텍스트 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-threshold",
   "metadata": {},
   "source": [
    "관사 a, an, the를 제외한 길이가 1인 단어는 모두 제거하기\n",
    "\n",
    "중복되는 문장 제거하기는 오히려 성능의 저하가 발생하여 중복제거는 안하는 것이 좋다는 것을 알았습니다.  \n",
    "중복 제거 전 : loss: 3.5905 - val_loss: 3.8269  \n",
    "중복 제거 후 : loss: 3.9458 - val_loss: 4.1933\n",
    "\n",
    "start 토큰과 end토큰을 없에고 하는것이 더 학습이 잘됩니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
